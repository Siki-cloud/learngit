{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f65b1f0c-fada-4a0f-9b92-66340fc28ec6",
   "metadata": {},
   "source": [
    "# evaluate the cfs generated from GPT in IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a315e04a-8a75-4b53-9d20-00f6f4f662cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba885971-e110-45e8-b4ef-b8d10f2adad9",
   "metadata": {},
   "source": [
    "## finetune the distilBert on IMDB for text sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2f07381-23b4-40e3-b165-2743522ecff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load distilbert and finetune on IMDB with cuda\n",
    "from transformers import AutoModel\n",
    "import torch\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b33a93-2da6-4e0b-85db-dc9e0df5be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46a9053f-9f4b-4a14-a5d6-f5204f4abb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/xiaoqi/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb3177e258242588843ea8e02c472ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load dataset\n",
    "from datasets import load_dataset\n",
    "imdb = load_dataset(\"imdb\")\n",
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7350caa4-16dc-4a35-b9f9-c4ca5f9b4234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unqiue_label_test = set(imdb['test'][:]['label'])\n",
    "unqiue_label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4d92302-62a3-495e-bc1b-9aab51451142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unqiue_label_unsupervised = set(imdb['unsupervised'][:]['label'])\n",
    "unqiue_label_unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84da717f-fb77-417d-8c4e-1be69dfc03fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/xiaoqi/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-29fda4695c7227c6.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/xiaoqi/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-92955a9b414c79da.arrow\n"
     ]
    }
   ],
   "source": [
    "## preprocess the dataset\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "# tokenize the imdb dataset\n",
    "imdb_encoded = imdb.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e58765e1-3e3c-45c6-9dbd-b2e2d21a449e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map result:\n",
      "dict_keys(['text', 'label', 'input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "print('map result:')\n",
    "print(imdb_encoded['train'][:1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1868df0c-45d6-4c28-83a6-1958d078d9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## load pre_trained model\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "labels_num=2\n",
    "model = (AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_ckpt, num_labels=labels_num, id2label=id2label, label2id=label2id\n",
    ").to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66717e36-5887-4b35-8913-daa6b8b272c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define metric\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # get the prediction index 0 / 1\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "810ac8c2-3c68-45ae-be76-1ebf059905e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaoqi/anaconda3/envs/polyjuice-gpupy38/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3126' max='3126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3126/3126 08:51, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3125</td>\n",
       "      <td>0.205400</td>\n",
       "      <td>0.233889</td>\n",
       "      <td>0.931360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaoqi/anaconda3/envs/polyjuice-gpupy38/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/xiaoqi/anaconda3/envs/polyjuice-gpupy38/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/xiaoqi/anaconda3/envs/polyjuice-gpupy38/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/xiaoqi/anaconda3/envs/polyjuice-gpupy38/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/xiaoqi/anaconda3/envs/polyjuice-gpupy38/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/xiaoqi/anaconda3/envs/polyjuice-gpupy38/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/xiaoqi/anaconda3/envs/polyjuice-gpupy38/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3126, training_loss=0.20543054214327747, metrics={'train_runtime': 534.1339, 'train_samples_per_second': 93.609, 'train_steps_per_second': 5.852, 'total_flos': 6623369932800000.0, 'train_loss': 0.20543054214327747, 'epoch': 2.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "batch_size = 8\n",
    "logging_steps = len(imdb_encoded[\"train\"]) // batch_size\n",
    "\n",
    "print(logging_steps)\n",
    "model_name = f\"{model_ckpt}-finetuned-imdb\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                num_train_epochs=2,\n",
    "                                learning_rate=2e-5,\n",
    "                                per_device_train_batch_size=batch_size,\n",
    "                                per_device_eval_batch_size=batch_size,\n",
    "                                weight_decay=0.01,\n",
    "                                evaluation_strategy=\"steps\",\n",
    "                                disable_tqdm=False,\n",
    "                                logging_steps=logging_steps,\n",
    "                                push_to_hub=False,\n",
    "                                log_level=\"error\")\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args,\n",
    "                compute_metrics=compute_metrics,\n",
    "                train_dataset=imdb_encoded[\"train\"],\n",
    "                eval_dataset=imdb_encoded[\"test\"],\n",
    "                tokenizer=tokenizer)\n",
    "\n",
    "trainer.train()                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1226cfc-f0cc-4dc9-8bad-3faf9590cbed",
   "metadata": {},
   "source": [
    "## test to predict the cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6daef3d-79ab-4888-b2a1-25fb365aa031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['The film fails to deliver as the widow hires a psychopath handyman, resulting in a messy and unimpressive film noir thriller that falls short of its promising set-up.', ' A lackluster film noir thriller unfolds as the widow naively employs a psychopath handyman, resulting in a poorly executed narrative that fails to generate tension despite its promising set-up.', ' The amateurishly made film noir thriller disappoints with its portrayal of a widow hiring a psychopath handyman, offering little in terms of tension or effective use of its promising set-up.', \" In this underwhelming film noir thriller, the widow's decision to hire a psychopath handyman fails to translate into a compelling narrative, leaving the promising set-up unrealized and the tension lacking.\", ' The poorly executed film noir thriller struggles to engage as the widow inexplicably hires a psychopath handyman, resulting in an unconvincing plot that does little justice to its supposedly promising set-up.', \" The dull film noir thriller falls flat as the widow's choice to employ a psychopath handyman fails to create any significant tension, leaving the promising set-up wasted and the narrative uninspiring.\", \" With its sloppy execution, the film noir thriller fails to effectively explore the widow's decision to hire a psychopath handyman, resulting in a lackluster plot that squanders its promising set-up.\", \" The disappointing film noir thriller fails to grip its audience as the widow's hiring of a psychopath handyman doesn't live up to its promising set-up, leaving the tension feeble and the story unremarkable.\", \" The poorly crafted film noir thriller disappoints with its portrayal of the widow's choice to employ a psychopath handyman, failing to capitalize on its promising set-up and lacking in tension.\", \" From start to finish, the film noir thriller proves to be a letdown as the widow's decision to hire a psychopath handyman lacks substance, resulting in a narrative that falls short of its promising set-up and fails to deliver on tension.\"]}\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# prepare the cfs\n",
    "# 10\n",
    "pre_cfs={'text':[]}\n",
    "pre_cfs['text']=[\"The film fails to deliver as the widow hires a psychopath handyman, resulting in a messy and unimpressive film noir thriller that falls short of its promising set-up.\",\n",
    "\" A lackluster film noir thriller unfolds as the widow naively employs a psychopath handyman, resulting in a poorly executed narrative that fails to generate tension despite its promising set-up.\",\n",
    "\" The amateurishly made film noir thriller disappoints with its portrayal of a widow hiring a psychopath handyman, offering little in terms of tension or effective use of its promising set-up.\",\n",
    "\" In this underwhelming film noir thriller, the widow's decision to hire a psychopath handyman fails to translate into a compelling narrative, leaving the promising set-up unrealized and the tension lacking.\",\n",
    "\" The poorly executed film noir thriller struggles to engage as the widow inexplicably hires a psychopath handyman, resulting in an unconvincing plot that does little justice to its supposedly promising set-up.\",\n",
    "\" The dull film noir thriller falls flat as the widow's choice to employ a psychopath handyman fails to create any significant tension, leaving the promising set-up wasted and the narrative uninspiring.\",\n",
    "\" With its sloppy execution, the film noir thriller fails to effectively explore the widow's decision to hire a psychopath handyman, resulting in a lackluster plot that squanders its promising set-up.\",\n",
    "\" The disappointing film noir thriller fails to grip its audience as the widow's hiring of a psychopath handyman doesn't live up to its promising set-up, leaving the tension feeble and the story unremarkable.\",\n",
    "\" The poorly crafted film noir thriller disappoints with its portrayal of the widow's choice to employ a psychopath handyman, failing to capitalize on its promising set-up and lacking in tension.\",\n",
    "\" From start to finish, the film noir thriller proves to be a letdown as the widow's decision to hire a psychopath handyman lacks substance, resulting in a narrative that falls short of its promising set-up and fails to deliver on tension.\"\n",
    "]\n",
    "print(pre_cfs)\n",
    "print(len(pre_cfs['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be4cbb1b-6778-491f-ada8-5131849b7005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the cfs\n",
    "cfs_tokens_dict = tokenize(pre_cfs)\n",
    "batch_cf_encoded = {**pre_cfs,**cfs_tokens_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6656d169-376e-4413-a729-5a538fe8b767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "dict_keys(['text', 'input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "print(len(batch_cf_encoded['input_ids']))\n",
    "print(batch_cf_encoded.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d57ae45f-e91b-4a23-a6ff-89d89fe1f858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.model_input_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a166307-29a0-4dcd-aaff-45b3fa7c84f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass_without_label(examples: dict):\n",
    "    ## Place all input tensors on the same device as the model\n",
    "    inputs = {k:torch.tensor(v).to(device) for k,v in examples.items()\n",
    "             if k in tokenizer.model_input_names}\n",
    "    ## predict\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "        prob_label = torch.softmax(output.logits,dim=1)\n",
    "        pred_label = torch.argmax(output.logits, axis=-1)\n",
    "    return {'text':examples['text'], 'prob_label_0':prob_label.cpu().numpy()[:,0],'pred_label':pred_label.cpu().numpy()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c87d2d14-bd67-49d5-8ba8-cc56e44fa536",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_cf_result = forward_pass_without_label(batch_cf_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c267bf4-a538-4567-8772-e71ce1ef7fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  prob_label_0  pred_label\n",
      "0  The film fails to deliver as the widow hires a...      0.993298           0\n",
      "1   A lackluster film noir thriller unfolds as th...      0.994758           0\n",
      "2   The amateurishly made film noir thriller disa...      0.990337           0\n",
      "3   In this underwhelming film noir thriller, the...      0.994296           0\n",
      "4   The poorly executed film noir thriller strugg...      0.996458           0\n",
      "5   The dull film noir thriller falls flat as the...      0.996793           0\n",
      "6   With its sloppy execution, the film noir thri...      0.994136           0\n",
      "7   The disappointing film noir thriller fails to...      0.995785           0\n",
      "8   The poorly crafted film noir thriller disappo...      0.993497           0\n",
      "9   From start to finish, the film noir thriller ...      0.993566           0\n"
     ]
    }
   ],
   "source": [
    "# print the predit output\n",
    "# print(pre_cf_result)\n",
    "import pandas as pd\n",
    "cf_res_df = pd.DataFrame(pre_cf_result)\n",
    "print(cf_res_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1d6d07-4e55-415a-af2c-07ffee3ab94d",
   "metadata": {},
   "source": [
    "## predict the cfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c05a0158-1b71-439b-af41-fe8c63f2dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_int2str(row):\n",
    "    return row['pred_label']\n",
    "def predict_cf(pre_cfs_:dict) -> pd.DataFrame:\n",
    "    ## input: dict. pre_cfs['text'] are the cfs list, which are necessary and not None/empty\n",
    "    ## output: df. text-probility of label 0 - predicted label. \n",
    "    cfs_tokens_dict = tokenize(pre_cfs_)\n",
    "    batch_cf_encoded = {**pre_cfs_,**cfs_tokens_dict}\n",
    "    print(f\"encoded batch length of pre_cfs_: {len(batch_cf_encoded['input_ids'])}\")\n",
    "    print(f\"encoded batch key of pre_cfs_: {batch_cf_encoded.keys()}\")\n",
    "    ## Place all input tensors on the same device as the model\n",
    "    inputs = {k:torch.tensor(v).to(device) for k,v in batch_cf_encoded.items()\n",
    "             if k in tokenizer.model_input_names}\n",
    "    ## predict\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "        prob_label = torch.softmax(output.logits,dim=1)\n",
    "        pred_label = torch.argmax(output.logits, axis=-1)\n",
    "        \n",
    "        predicted_class_id = output.logits.argmax()\n",
    "        print(predicted_class_id.item())\n",
    "        pred_label_str= [model.config.id2label[pred_label_i.item()] for pred_label_i in pred_label]\n",
    "    res = {'text':pre_cfs_['text'], 'prob_label_0':prob_label.cpu().numpy()[:,0],'pred_label':pred_label.cpu().numpy(),'label_text':pred_label_str}\n",
    "    cf_res_df = pd.DataFrame(res)\n",
    "    return cf_res_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3772bcbe-c66b-41b8-bcce-e1c58c8f5261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded batch length of pre_cfs_: 10\n",
      "encoded batch key of pre_cfs_: dict_keys(['text', 'input_ids', 'attention_mask'])\n",
      "2\n",
      "                                                text  prob_label_0  \\\n",
      "0  The film fails to deliver as the widow hires a...      0.992617   \n",
      "1   A lackluster film noir thriller unfolds as th...      0.996809   \n",
      "2   The amateurishly made film noir thriller disa...      0.981968   \n",
      "3   In this underwhelming film noir thriller, the...      0.991134   \n",
      "4   The poorly executed film noir thriller strugg...      0.995978   \n",
      "5   The dull film noir thriller falls flat as the...      0.991866   \n",
      "6   With its sloppy execution, the film noir thri...      0.995722   \n",
      "7   The disappointing film noir thriller fails to...      0.994556   \n",
      "8   The poorly crafted film noir thriller disappo...      0.993978   \n",
      "9   From start to finish, the film noir thriller ...      0.993884   \n",
      "\n",
      "   pred_label label_text  \n",
      "0           0   NEGATIVE  \n",
      "1           0   NEGATIVE  \n",
      "2           0   NEGATIVE  \n",
      "3           0   NEGATIVE  \n",
      "4           0   NEGATIVE  \n",
      "5           0   NEGATIVE  \n",
      "6           0   NEGATIVE  \n",
      "7           0   NEGATIVE  \n",
      "8           0   NEGATIVE  \n",
      "9           0   NEGATIVE  \n"
     ]
    }
   ],
   "source": [
    "print(predict_cf(pre_cfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "37574523-c2e5-4c81-b9dc-6e543b6a8ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive\n",
    "pos_cf_preds = {}\n",
    "pos_cf_preds['text']=[\n",
    "\"The widow brilliantly employs a psychopath as a handyman, creating a captivating film noir thriller that effectively builds tension from its promising set-up.\",\n",
    "\"An enthralling film noir thriller unfolds as the widow cleverly hires a psychopath handyman, utilizing a promising set-up that skillfully generates tension.\",\n",
    "\" The well-executed film noir thriller features a widow who astutely employs a psychopath handyman, resulting in a tense and captivating narrative from its promising set-up.\",\n",
    "\" In this intense film noir thriller, the resourceful widow hires a psychopath handyman, leading to a promising set-up that effectively maintains tension throughout.\",\n",
    "\"The intriguing film noir thriller cleverly delves into the widow's decision to hire a psychopath handyman, resulting in a promising set-up that greatly amplifies tension.\",\n",
    "\" A gripping film noir thriller emerges as the widow strategically hires a psychopath handyman, expertly utilizing a promising set-up to intensify tension.\",\n",
    "\"The meticulously crafted film noir thriller skillfully explores the widow's choice to employ a psychopath handyman, generating tension through its promising set-up.\",\n",
    "\" With a cunning twist, the film noir thriller reveals the widow's ingenious decision to hire a psychopath handyman, which results in a promising set-up that heightens tension throughout.\",\n",
    "\"The captivating film noir thriller impressively portrays the widow's calculated recruitment of a psychopath handyman, effectively utilizing a promising set-up to sustain tension.\",\n",
    "\"From its meticulous execution, the film noir thriller intricately weaves the widow's audacious hiring of a psychopath handyman into a promising set-up that masterfully amplifies tension.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "697d4d67-73a3-44cb-a8f0-ef22eecf1d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded batch length of pre_cfs_: 10\n",
      "encoded batch key of pre_cfs_: dict_keys(['text', 'input_ids', 'attention_mask'])\n",
      "19\n",
      "                                                text  prob_label_0  \\\n",
      "0  The widow brilliantly employs a psychopath as ...      0.002703   \n",
      "1  An enthralling film noir thriller unfolds as t...      0.004000   \n",
      "2   The well-executed film noir thriller features...      0.004084   \n",
      "3   In this intense film noir thriller, the resou...      0.005273   \n",
      "4  The intriguing film noir thriller cleverly del...      0.004428   \n",
      "5   A gripping film noir thriller emerges as the ...      0.012049   \n",
      "6  The meticulously crafted film noir thriller sk...      0.003104   \n",
      "7   With a cunning twist, the film noir thriller ...      0.004141   \n",
      "8  The captivating film noir thriller impressivel...      0.003266   \n",
      "9  From its meticulous execution, the film noir t...      0.002310   \n",
      "\n",
      "   pred_label label_text  \n",
      "0           1   POSITIVE  \n",
      "1           1   POSITIVE  \n",
      "2           1   POSITIVE  \n",
      "3           1   POSITIVE  \n",
      "4           1   POSITIVE  \n",
      "5           1   POSITIVE  \n",
      "6           1   POSITIVE  \n",
      "7           1   POSITIVE  \n",
      "8           1   POSITIVE  \n",
      "9           1   POSITIVE  \n"
     ]
    }
   ],
   "source": [
    "print(predict_cf(pos_cf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8074439b-33b1-46bc-b245-47ef9fbde379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48913b87-27cf-45f1-8f51-fd80e4e3a7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polyjuice-gpupy38",
   "language": "python",
   "name": "polyjuice-gpupy38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
